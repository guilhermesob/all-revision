from pyspark import SparkContext

# Check if a SparkContext already exists, if not create one
if 'spark_contexto' not in globals() or spark_contexto._jsc is None:
    spark_contexto = SparkContext()

# Recreate the lista_rdd in the current Spark context
lista = [1,2,3,4,5,3]
lista_rdd = spark_contexto.parallelize(lista)

par_ordenado = lambda numero: (numero %2, numero,numero*10)
lista_rdd.flatMap(par_ordenado).collect()
#[1,10,2,20,3,30,4,40,5,50,3,30]
lista_rdd.map(par_ordenado).collect() # Add parentheses to call the collect method
#[(1,10),(2,20), (3,30) ,(4,40), (5,50) ,(3,30)]
#spark_contexto.stop()  # It's generally better to keep the SparkContext running throughout your session
